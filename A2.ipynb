{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Data Cleaning\n",
    "## Group 105\n",
    "- Natasa Bolic (300241734)\n",
    "- Brent Palmer (300193610)\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Clean Data Checker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Paragraph here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Url:** https://www.kaggle.com/datasets/ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training <br>\n",
    "**Name:** Cafe Sales - Dirty Data for Cleaning Training <br>\n",
    "**Author:** Ahmed Mohamed <br>\n",
    "**Purpose:** The dirty cafe sales dataset was fabricated to practice data cleaning, deliberately including missing data, inconsistencies, and errors. The Kaggle description specifies that the dataset \"can be used to practice cleaning techniques, data wrangling, and feature engineering.\"<br>\n",
    "**Shape:** There are 10,000 rows and 8 columns. (10000, 8)<br>\n",
    "**Features:** \n",
    "- `Transaction ID` (categorical): A unique id assigned to each transaction.\n",
    "- `Item` (categorical): The name of the purchased item.\n",
    "- `Quantity` (numerical): The count of the purchased item.\n",
    "- `Price Per Unit` (numerical): The price of one unit of the purchased item, measured in dollars.\n",
    "- `Total Spent` (numerical): The total amount spent in the transaction, measured in dollars. (Quantity * Price Per Unit)\n",
    "- `Payment Method` (categorical): The transaction's method of payment.\n",
    "- `Location` (categorical): The location of the transaction.\n",
    "- `Transaction Date` (numerical): The transaction date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset and Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID    Item Quantity Price Per Unit Total Spent  Payment Method  \\\n",
       "0    TXN_1961373  Coffee        2            2.0         4.0     Credit Card   \n",
       "1    TXN_4977031    Cake        4            3.0        12.0            Cash   \n",
       "2    TXN_4271903  Cookie        4            1.0       ERROR     Credit Card   \n",
       "3    TXN_7034554   Salad        2            5.0        10.0         UNKNOWN   \n",
       "4    TXN_3160411  Coffee        2            2.0         4.0  Digital Wallet   \n",
       "\n",
       "   Location Transaction Date  \n",
       "0  Takeaway       2023-09-08  \n",
       "1  In-store       2023-05-16  \n",
       "2  In-store       2023-07-19  \n",
       "3   UNKNOWN       2023-04-27  \n",
       "4  In-store       2023-06-11  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the dataset from a public repository\n",
    "url = \"https://raw.githubusercontent.com/Natasa127/CSI4142-A2/main/dirty_cafe_sales.csv\"\n",
    "sales = pd.read_csv(url)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    10000 non-null  object\n",
      " 1   Item              9667 non-null   object\n",
      " 2   Quantity          9862 non-null   object\n",
      " 3   Price Per Unit    9821 non-null   object\n",
      " 4   Total Spent       9827 non-null   object\n",
      " 5   Payment Method    7421 non-null   object\n",
      " 6   Location          6735 non-null   object\n",
      " 7   Transaction Date  9841 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Data Type Errors\n",
    "\n",
    "This test checks the data type of an attribute whose entries should be numerical (either an integer or a float).\n",
    "\n",
    "**References:** <br>\n",
    "Converting to numeric: https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html <br>\n",
    "Setting the type: https://www.geeksforgeeks.org/python-pandas-dataframe-astype/ <br>\n",
    "Selecting rows in one dataframe but not in another: https://discovery.cs.illinois.edu/guides/DataFrame-Row-Selection/dataframe-isin-selection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be edited by the user\n",
    "attributes = ['Quantity', 'Price Per Unit', 'Total Spent']\n",
    "datatypes = ['int', 'float']\n",
    "\n",
    "test_attribute = 'Quantity'\n",
    "test_datatype = 'int'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9521 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    9521 non-null   object\n",
      " 1   Item              9206 non-null   object\n",
      " 2   Quantity          9521 non-null   int32 \n",
      " 3   Price Per Unit    9349 non-null   object\n",
      " 4   Total Spent       9353 non-null   object\n",
      " 5   Payment Method    7074 non-null   object\n",
      " 6   Location          6412 non-null   object\n",
      " 7   Transaction Date  9371 non-null   object\n",
      "dtypes: int32(1), object(7)\n",
      "memory usage: 632.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Error check\n",
    "def type_filter(df, col, datatype):\n",
    "    # Creates a copy so that the original dataset is not modified\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "    # Converts numeric data to a numeric type and sets all other values to NaN\n",
    "    df_filtered[col] = pd.to_numeric(df_filtered[col], errors='coerce')\n",
    "    # Removes NaN values to leave only numerical values\n",
    "    df_filtered = df_filtered.dropna(subset=[col]).copy()\n",
    "    \n",
    "    if datatype == 'int':\n",
    "        # Takes only the integer values\n",
    "        df_filtered = df_filtered[df_filtered[col] % 1 == 0].copy()\n",
    "\n",
    "        # Converts the type to integer (as opposed to float)\n",
    "        df_filtered[col] = df_filtered[col].astype(datatype)\n",
    "\n",
    "    # Returns the filtered dataset\n",
    "    return df_filtered\n",
    "\n",
    "checked_sales = type_filter(sales, test_attribute, test_datatype)\n",
    "checked_sales.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TXN_3522028</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TXN_5522862</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TXN_2080895</td>\n",
       "      <td>Cake</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-04-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>TXN_8501819</td>\n",
       "      <td>Juice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>TXN_2148617</td>\n",
       "      <td>Juice</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-01-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Transaction ID      Item Quantity Price Per Unit Total Spent  \\\n",
       "20     TXN_3522028  Smoothie    ERROR            4.0        20.0   \n",
       "55     TXN_5522862    Cookie    ERROR            1.0         2.0   \n",
       "57     TXN_2080895      Cake  UNKNOWN            3.0         3.0   \n",
       "66     TXN_8501819     Juice      NaN            3.0         6.0   \n",
       "117    TXN_2148617     Juice    ERROR            3.0         9.0   \n",
       "\n",
       "     Payment Method  Location Transaction Date  \n",
       "20             Cash  In-store       2023-04-04  \n",
       "55      Credit Card  Takeaway       2023-03-19  \n",
       "57   Digital Wallet  In-store       2023-04-19  \n",
       "66             Cash       NaN       2023-03-30  \n",
       "117  Digital Wallet   UNKNOWN       2023-01-10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accesses entries with invalid datatypes for the given column\n",
    "invalid_type = sales[~sales.index.isin(checked_sales.index)]\n",
    "# Obtains number of invalid entries\n",
    "print(len(invalid_type))\n",
    "# Displays 5 invalid entries\n",
    "invalid_type.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "There are 479 rows with a quantity that is not an integer. This seems to occur when the value is unknown, and replaced by a string such as 'UNKNOWN' or 'ERROR' instead. For example, see the two rows below:\n",
    "\n",
    "<u>Transaction ID / Item / Quantity\n",
    "Transaction ID\t/ Item\t/ Quantity \t/ Price Per Unit\tTotal Spent\t/ Payment Method\t/ Location\t/ Transaction Date</u>\n",
    "\n",
    "TXN_3522028\t/ Smoothie\t/ ERROR\t/ 4.0\t/ 20.0\t/ Cash\t/ In-store\t/ 2023-04-04\n",
    "\n",
    "TXN_5522862\t/ Cookie\t/ ERROR\t/ 1.0\t/ 2.0\t/ Credit Card\t/ Takeaway\t/ 2023-03-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform data type checks for the rest of the numerical attributes so that the columns have the correct datatype in subsequent checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8544 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Transaction ID    8544 non-null   object \n",
      " 1   Item              8261 non-null   object \n",
      " 2   Quantity          8544 non-null   int32  \n",
      " 3   Price Per Unit    8544 non-null   float64\n",
      " 4   Total Spent       8544 non-null   float64\n",
      " 5   Payment Method    6354 non-null   object \n",
      " 6   Location          5762 non-null   object \n",
      " 7   Transaction Date  8415 non-null   object \n",
      "dtypes: float64(2), int32(1), object(5)\n",
      "memory usage: 567.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Filter by type for the remaining numerical attributes\n",
    "checked_sales = type_filter(checked_sales, attributes[1], datatypes[1])\n",
    "checked_sales = type_filter(checked_sales, attributes[2], datatypes[1])\n",
    "checked_sales.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Range Errors\n",
    "\n",
    "This test checks the range of a numerical variable, which consists of checking if the value of the variable is within the minimum and maximum acceptable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be edited by the user\n",
    "attributes = ['Quantity', 'Price Per Unit', 'Total Spent']\n",
    "\n",
    "test_attribute = 'Quantity'\n",
    "\n",
    "minimum = 1\n",
    "\n",
    "maximum = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Transaction ID, Item, Quantity, Price Per Unit, Total Spent, Payment Method, Location, Transaction Date]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error check\n",
    "\n",
    "# Extract values that are either above the maximum acceptable value or below the minimum acceptable value\n",
    "invalid_range = checked_sales[(checked_sales[test_attribute] > maximum) | (checked_sales[test_attribute] < minimum)]\n",
    "invalid_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "There are no values for quantity that are outside of the acceptable range.\n",
    "\n",
    "TODO: maybe we should add invalid entries (like -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Format Errors\n",
    "\n",
    "This test checks that dates are stored in the correct format, i.e. YYYY-MM-DD.\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "Convert to datetime: https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be edited by the user\n",
    "attribute = 'Transaction Date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN_2602893</td>\n",
       "      <td>Smoothie</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID      Item  Quantity  Price Per Unit  Total Spent  \\\n",
       "0    TXN_1961373    Coffee         2             2.0          4.0   \n",
       "1    TXN_4977031      Cake         4             3.0         12.0   \n",
       "3    TXN_7034554     Salad         2             5.0         10.0   \n",
       "4    TXN_3160411    Coffee         2             2.0          4.0   \n",
       "5    TXN_2602893  Smoothie         5             4.0         20.0   \n",
       "\n",
       "   Payment Method  Location Transaction Date  \n",
       "0     Credit Card  Takeaway       2023-09-08  \n",
       "1            Cash  In-store       2023-05-16  \n",
       "3         UNKNOWN   UNKNOWN       2023-04-27  \n",
       "4  Digital Wallet  In-store       2023-06-11  \n",
       "5     Credit Card       NaN       2023-03-31  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error Check\n",
    "\n",
    "def format_filter(df, col):\n",
    "    df_filtered = df.copy()\n",
    "    \n",
    "    # Sets all values that are not dates into NaT (not a time)\n",
    "    df_filtered[col] = pd.to_datetime(df_filtered[col], yearfirst = True, errors='coerce')\n",
    "    \n",
    "    # Removes NaN values to leave only the values in the right format\n",
    "    df_filtered = df_filtered.dropna(subset=[col]).copy()\n",
    "    \n",
    "    # Print the DataFrame to check the result\n",
    "    return df_filtered\n",
    "\n",
    "new_checked_sales = format_filter(checked_sales, attribute)\n",
    "new_checked_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TXN_3051279</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>TXN_7640952</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TXN_7710508</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>TXN_2091733</td>\n",
       "      <td>Salad</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In-store</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>TXN_7028009</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Transaction ID      Item  Quantity  Price Per Unit  Total Spent  \\\n",
       "11     TXN_3051279  Sandwich         2             4.0          8.0   \n",
       "29     TXN_7640952      Cake         4             3.0         12.0   \n",
       "33     TXN_7710508   UNKNOWN         5             1.0          5.0   \n",
       "77     TXN_2091733     Salad         1             5.0          5.0   \n",
       "103    TXN_7028009      Cake         4             3.0         12.0   \n",
       "\n",
       "     Payment Method  Location Transaction Date  \n",
       "11      Credit Card  Takeaway            ERROR  \n",
       "29   Digital Wallet  Takeaway            ERROR  \n",
       "33             Cash       NaN            ERROR  \n",
       "77              NaN  In-store              NaN  \n",
       "103             NaN  Takeaway            ERROR  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accesses entries with invalid format for the given column\n",
    "invalid_format = checked_sales[~checked_sales.index.isin(new_checked_sales.index)]\n",
    "# Obtains number of invalid entries\n",
    "print(len(invalid_format))\n",
    "# Displays 5 invalid entries\n",
    "invalid_format.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "There are 385 rows where the transaction date is in the wrong format. For example, see the two rows below:\n",
    "\n",
    "<u>Transaction ID / Item / Quantity\n",
    "Transaction ID\t/ Item\t/ Quantity \t/ Price Per Unit\tTotal Spent\t/ Payment Method\t/ Location\t/ Transaction Date</u>\n",
    "\n",
    "TXN_3051279\t/ Sandwich\t/ 2\t/ 4.0\t/ 8.0\t/ Credit Card\t/ Takeaway\t/ ERROR\n",
    "\n",
    "TXN_7640952\t/ Cake\t/ 4\t/ 3.0\t/ 12.0\t/ Digital Wallet\t/ Takeaway\t/ ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Paragraph here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Url:** https://www.kaggle.com/datasets/uciml/autompg-dataset <br>\n",
    "**Name:** Auto-mpg Dataset <br>\n",
    "**Author:** UCI Machine Learning Repository (originally from StatLib library, maintained at Carnegie Mellon University) <br>\n",
    "**Purpose:** The dataset includes the technical specifications of cars. The original purpose of collection is not explicitly listed on Kaggle, but it appears to have been collected to evaluate how fuel consumption relates to various other attributes of vehicles (e.g., horsepower, weight). In 1993, Ross Quinlan used the dataset to train a machine learning model to predict fuel consumption based on the other eight features.<br>\n",
    "**Shape:** There are 398 rows and 9 columns. (398, 9)<br>\n",
    "**Features:** Further explanation of the features retrieved from https://code.datasciencedojo.com/tshrivas/dojoHub/tree/master/Auto%20MPG%20Data%20Set\n",
    "- `mpg` (numerical): The vehicle's fuel efficiency, measured in miles per gallon (mpg).\n",
    "- `cylinders` (categorical): The number of cylinders in the vehicle's engine.\n",
    "- `displacement` (numerical): The total volume of the cylinders in the vehicle, measured in cubic inches.\n",
    "- `horsepower` (numerical): A measurement of the vehicle's engine's power.\n",
    "- `weight` (numerical): The weight of the vehicle, measured in pounds (lbs).\n",
    "- `acceleration` (numerical): Time to go from 0 to 60 miles per hour, measured in seconds.\n",
    "- `model year` (categorical): The year of release of the vehicle.\n",
    "- `origin` (categorical): The region of manufacturing.\n",
    "    - 1: USA\n",
    "    - 2: Europe\n",
    "    - 3: Japan\n",
    "- `car name` (categorical): The name of the vehicle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Values:** Yes, there are missing values. In particular, horsepower has 6 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset and Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0          70   \n",
       "1  15.0          8         350.0        165    3693          11.5          70   \n",
       "2  18.0          8         318.0        150    3436          11.0          70   \n",
       "3  16.0          8         304.0        150    3433          12.0          70   \n",
       "4  17.0          8         302.0        140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the dataset from a public repository\n",
    "url = \"https://raw.githubusercontent.com/Natasa127/CSI4142-A2/refs/heads/main/auto-mpg.csv\"\n",
    "auto_df = pd.read_csv(url)\n",
    "auto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car name      398 non-null    object \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "auto_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Cleaning\n",
    "Since there are only six missing values in the entire dataset (1.5% of the rows), we decided to use the listwise removal approach to delete these rows. The assignment requires simulating missing values (as indicated by part b), which enables us to do cross validation since we know the true values of the data. Thus, deleting these six rows in advance will make the cross-validation approach possible. Since it is such a small amount of data, this deletion will not significantly impact our analysis.\n",
    "\n",
    "**References:** <br>\n",
    "Listwise removal: https://saturncloud.io/blog/how-to-remove-rows-with-specific-values-in-pandas-dataframe/ <br>\n",
    "Series equality: https://pandas.pydata.org/docs/reference/api/pandas.Series.eq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_df = auto_df.drop(auto_df[auto_df['horsepower'] == '?'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_df['horsepower'].eq('?').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The six rows have successfully been removed, and we are now ready for imputation and evaluation using cross-validation with simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation Test 1: Random Sample Imputation on Acceleration (Univariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Chosen Attribute\n",
    "\n",
    "We have chosen to test random sample imputation (univariate) on the acceleration attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Simulate Missing Values\n",
    "\n",
    "We are simulating missing acceleration values using the MCAR approach, where the missing acceleration values are chosen completely at random regardless of their own value or the values of the other attributes.\n",
    "\n",
    "We are simulating the missing values in a copy of the original DataFrame such that we can evaluate the imputation accuracy afterwards by comparing the imputed acceleration values with the true acceleration values.\n",
    "\n",
    "**References:** <br>\n",
    "MCAR: https://www.kaggle.com/code/yassirarezki/handling-missing-data-mcar-mar-and-mnar-part-i <br>\n",
    "Loc Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html <br>\n",
    "Copy Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html <br>\n",
    "Fixing Random Seed: https://stackoverflow.com/questions/21494489/what-does-numpy-random-seed0-do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of the DataFrame\n",
    "missing_acceleration_df = auto_df.copy()\n",
    "\n",
    "# Set the random seed to make the results reproducible (comment this out to try on truly random missing values)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate a series that holds True for rows that will be missing, and False for rows that will persist\n",
    "missing_percent = 0.1\n",
    "missing_values = np.random.choice([True, False], len(auto_df), p=[missing_percent, 1 - missing_percent])\n",
    "\n",
    "# Replace the acceleration with NaN where the missing_values series is True\n",
    "missing_acceleration_df.loc[missing_values, \"acceleration\"] = np.nan\n",
    "\n",
    "# Check to see if values are missing\n",
    "missing_acceleration_df['acceleration'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Program an Imputation Approach to Replace the Missing Values\n",
    "\n",
    "We have chosen random sample imputation as our first imputation approach. Random sample imputation is a univariate technique.\n",
    "\n",
    "**References:** <br>\n",
    "Sample Documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save a series of the non-missing acceleration values\n",
    "acceleration_values = missing_acceleration_df.loc[missing_acceleration_df['acceleration'].notna(), 'acceleration']\n",
    "\n",
    "# Sample a number of non-missing acceleration values with replacement equal to the number of missing values\n",
    "# Note that random state is set to one to make the results reproducible. This can be removed for truly random samples\n",
    "sampled_acceleration_values = acceleration_values.sample(missing_acceleration_df['acceleration'].isna().sum(), replace=True, random_state=1).values\n",
    "\n",
    "# Replace the missing values with sampled acceleration values\n",
    "missing_acceleration_df.loc[missing_values, \"acceleration\"] = sampled_acceleration_values\n",
    "\n",
    "# Check to see if values are missing\n",
    "missing_acceleration_df['acceleration'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Evaluate to What Extent Your Approach is Finding the Missing Values\n",
    "\n",
    "Since we are using the cross-validation with simulation approach where we simulate missing data, we can compare our imputed values to the true values.\n",
    "\n",
    "##### Evaluation Using MSE\n",
    "\n",
    "We will first use the Mean Squared Error (MSE) approach, where we take the average of the squared difference of each imputed value with the respective true value.\n",
    "\n",
    "**References:** <br>\n",
    "Mean Squared Error: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.729999999999997"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First determine the original values of the missing data\n",
    "original_values = auto_df.loc[missing_values, 'acceleration'].values\n",
    "\n",
    "# Then determine the imputed values of the missing data\n",
    "imputed_values = missing_acceleration_df.loc[missing_values, 'acceleration'].values\n",
    "\n",
    "# Compute MSE\n",
    "mse = mean_squared_error(original_values, imputed_values)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the mean square error is 9.73 using random sample imputation. The MSE is not particularly intuitive to interpret as a standalone value since it is measured in squared units. A great way to interpret MSE is to compare it to the MSE of a baseline method, like median imputation. In the following cell we will perform median imputation, and compare the MSE values to evaluate the effectiveness of the random sampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.330512820512821"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the imputed values with NaN where the missing_values series is True.\n",
    "missing_acceleration_df.loc[missing_values, \"acceleration\"] = np.nan\n",
    "\n",
    "# Save the median of the non-missing acceleration values\n",
    "acceleration_median = missing_acceleration_df.loc[missing_acceleration_df['acceleration'].notna(), 'acceleration'].median()\n",
    "\n",
    "# Replace the missing values with median\n",
    "missing_acceleration_df.loc[missing_values, \"acceleration\"] = acceleration_median\n",
    "\n",
    "# Compute MSE\n",
    "original_values = auto_df.loc[missing_values, 'acceleration'].values\n",
    "imputed_values = missing_acceleration_df.loc[missing_values, 'acceleration'].values\n",
    "median_mse = mean_squared_error(original_values, imputed_values)\n",
    "median_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that random sampling gave an MSE of 9.73 and default value imputation using the median gave an MSE of 5.33, the random sampling approach is not very good comparatively in this case. \n",
    "\n",
    "##### Evaluation Using MAE\n",
    "\n",
    "A second approach to evaluation is Mean Absolute Error (MAE), which is more intuitive since the units of MAE are the same as the original data. MAE takes the average absolute difference between each imputed value with the respective true value.\n",
    "\n",
    "**References:** <br>\n",
    "Mean Squared Error: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6128205128205124"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = mean_absolute_error(original_values, imputed_values)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE is 2.61, which means that on average, the imputed acceleration had an error of 2.61 seconds. In the context of a vehicle's acceleration in seconds, this is not that bad.\n",
    "\n",
    "##### Evaluation Conclusion\n",
    "Despite the random sampling MSE being notably worse than the default value imputation using the median MSE, random sampling is still usable as seen through the reasonable MAE score of 2.61 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
